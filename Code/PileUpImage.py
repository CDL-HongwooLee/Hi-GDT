import subprocess as sp
import sys
import argparse
import os
import numpy as np
import pickle
import time
import multiprocessing as mp
from PIL import Image
from functools import partial
import itertools

def parse_args():
    parser = argparse.ArgumentParser(description = "", formatter_class = argparse.RawTextHelpFormatter)
    parser.add_argument('-b', dest = 'bedfile', required=True, help = 
    '''Path to the .bed file which includes specific regions for pileup analysis.
The 4th column should contain the label of each element.
    ''')
    parser.add_argument('-c', dest = 'chromSize', required=True, help = 
    '''Path to the .chrom.sizes file.
    ''')
    parser.add_argument('-f', dest = 'refile', required=True, help = 
    '''Path to the fragment.bed file which is composed of 'chromosome', 'fragment_start', 'fragment_end', 'fragment_number'.
The resolution of this file should match with that of matrix.pkl files.
Both fixed intervals and restriction fragment intervals can be used.
By default, this file is generated by HiGDT.py as {outdir}/{prefix}.{resolution}{BP/FRAG}.bed.
    ''') 
    parser.add_argument('-p', dest = 'prefix', required=True, help = 
    '''Prefix for naming the output file.
{outdir}/{prefix}.pkl will be generated.
    ''')
    parser.add_argument('-r', dest = 'resolution', required=True, type = int, help = 
    '''Resolution of input matrix.
    ''')
    parser.add_argument('-j', dest = 'juicertools', default = False, help = 
    '''Path to the juicer_tools.jar file. Not required if the "--skip" option is used.
    ''')
    parser.add_argument('-hic', dest = 'hic', default = False, help = 
    '''Path to the .hic file. Not required if the "--skip" option is used.
    ''')
    parser.add_argument('-n', dest = 'norm', default = "SCALE", help = 
    '''Normalization method. Choose one of ["NONE", "VC", "VC_SQRT", "KR", "SCALE"]. 
Not required if the "--skip" option is used.
Default = 'SCALE'.
    ''')
    parser.add_argument('--skip', dest = 'skip', action='store_true', help = 
    '''Use this flag to skip generating matrix.pkl file from a .hic file. 
You can use this flag if you've previously generated matrix.pkl file using or PileupGeneDomain.py or HiGDT.py.
if set, -i {matrix.pickle} option is required for input file.
    ''')
    parser.add_argument('-i', dest = 'infile', default = False, help = 
    '''Path to the input matrix.pkl file.
By default, this file is generated as {outdir}/{prefix}.{resolution}{BP/FRAG}.matrix.pkl by PileupGeneDomain.py or HiGDT.py.
    ''')
    parser.add_argument('-bf', dest = 'BP_FRAG', default = "BP", help = 
    '''The unit of resolution; basepair or restriction fragment.
Choose one of ["BP", "FRAG"].
Default = 'BP'.
    ''')
    parser.add_argument('-s', dest = 'imgSize', default=80, type = int, help = 
    '''The size of output image size. 
Each regions specified in .bed file will be resized to n*n matrix.
Too high value may cause memory problem. Recommend (20 - 80).
Default = 80.
    ''')
    parser.add_argument('-bs', dest = 'binSize', default=10, type = int, help = 
    '''Initial image resolution (bp).
The bin size of initial image before resizing.
Smaller value may cause memory problem and spend more time. 
10 is fine in Arabidopsis analysis.
Default = 10.
    ''')
    parser.add_argument('-pad', dest = 'padding', default=0.5, type = float, help = 
'''The padding size (compared to the size of target regions) to be visualized.
Up/downstream (padding * region_size) (bp) will be visualized as well as target_regions
The visualized window = padding * region_size * 2 + region_size.
Default = 0.5.
    ''')
    parser.add_argument('-o', dest = 'outdir', default = './', help = 
    '''Path to the output directory where whole output files will be written.
Default = './'.
    ''')
    parser.add_argument('-t', dest = 'threads', default = 1, type = int, help = 
    '''Number of threads to use. Ideally equal to the number of chromosomes.
Default = 1.
    ''')
    return parser.parse_args()

def MaketmpDir(outdir):
    if os.path.isdir(f'{outdir}') == False:
        os.mkdir(f'{outdir}')
    if os.path.isdir(f'{outdir}/tmp') == False:
        os.mkdir(f'{outdir}/tmp')

def AddBoundary(chromsize, bedfile, padding, outdir, prefix):
    chromLengthDic = {}
    with open(chromsize) as c1:
        for line in c1:
            chromLengthDic[line.split('\t')[0]] = line.rstrip().split('\t')[1]
    
    script = []
    for chrom in chromLengthDic:
        length = chromLengthDic[chrom]
        script.append(f"if ($1==\"{chrom}\" && $3 <= {length}) print; ")
    fullscript = 'else '.join(script)
    sp.run(f"less {bedfile} | awk '{{ print $1, int($2-($3-$2)*{padding}), int($3+($3-$2)*{padding}), $4, $5, $6}}' OFS='\t' | awk '$2 >= 1' | awk '{{{fullscript}}}' > {outdir}/tmp/{prefix}.region_addBoundary.txt", shell=True)    

def makeFragmentedGene(outdir, prefix, refile):
    sp.run(f'bedtools intersect -a {outdir}/tmp/{prefix}.region_addBoundary.txt -b {refile} -wo > {outdir}/tmp/{prefix}.FragmentedGene.txt', shell=True)
    sp.run(f'less {outdir}/tmp/{prefix}.FragmentedGene.txt | datamash groupby 1,2,3,4,5,6 min 10 max 10 > {outdir}/tmp/{prefix}.FragmentedGene_minMax.txt', shell=True)

    with open(f'{outdir}/tmp/{prefix}.FragmentedGene_minMax.txt') as f2:
        Gene_minMaxFragDic = {}
        for line in f2:
            chr_name, start, end, geneid, _, strand, minf, maxf = line.rstrip().split('\t')
            Gene_minMaxFragDic[geneid] = minf + '\t' + maxf

    with open(f'{outdir}/tmp/{prefix}.FragmentedGene.txt') as f3:
        RElengthDic = {}
        lines = f3.readlines()
        i=0
        while i <= len(lines)-1:
            gene_id = lines[i].split('\t')[3]
            length = int(lines[i].rstrip().split('\t')[10]) + 1  

            if i==0 or gene_id != lines[i-1].split('\t')[3]:
                geneLengthlist = [length]
                if i == len(lines)-1 or gene_id != lines[i+1].split('\t')[3]:
                    RElengthDic[gene_id] = geneLengthlist
            elif i == len(lines)-1 or gene_id != lines[i+1].split('\t')[3]:
                geneLengthlist.append(length)
                RElengthDic[gene_id] = geneLengthlist
            else:
                geneLengthlist.append(length)
            i += 1
    return Gene_minMaxFragDic, RElengthDic

def getVariables(chromsize, refile, bedfile):
    chromlist = sp.check_output(f'less {chromsize} | cut -f 1', shell=True, universal_newlines=True).rstrip().split('\n')
    chrStartFragNumDic = dict() ; chrEndFragNumDic = dict()
    chrStartEndFragList = sp.check_output(f'less {refile} | datamash groupby 1 min 4 max 4', shell=True, universal_newlines=True).strip().split('\n')
    for line in chrStartEndFragList:
        chr, start, end = line.rstrip().split('\t')
        chrStartFragNumDic[chr] = int(start)
        chrEndFragNumDic[chr] = int(end)

    startDic = dict() ; endDic = dict() ; strandDic = dict()
    with open(bedfile) as b1:
        for line in b1:
            _, start, end, geneid, _, strand = line.rstrip().split('\t')
            startDic[geneid] = start
            endDic[geneid] = end
            strandDic[geneid] = strand

    return chromlist, chrStartFragNumDic, chrEndFragNumDic, startDic, endDic, strandDic

def DumpMatrix(outdir, prefix, juicer_tools, norm, hic, res, bf, chromlist, t):
    sp.run(f"parallel -j {t} \"java -jar {juicer_tools} dump oe {norm} {hic} {{1}} {{1}} {bf} {res} {outdir}/tmp/{prefix}.{{1}}_{{1}}.{res}{bf}.txt\" ::: $(echo {' '.join(chromlist)})", shell=True)

def MakeIFpickleFiles(outdir, prefix, chrStartFragNumDic, chromlist, res, bf, t):

    pool = mp.Pool(processes=t)
    func_parallel = partial(MakeChrompickle, outdir, prefix, bf)
    pool.map(func_parallel, itertools.product(chromlist, zip([res], [chrStartFragNumDic])))
    pool.close()
    pool.join()
        
    mergedDic = dict()
    for chrom in chromlist:
        with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res}{bf}.matrix.pkl', 'rb') as pk:
            mergedDic[chrom] = pickle.load(pk)
    with open(f'{outdir}/{prefix}.{res}{bf}.matrix.pkl','wb') as pko:
        pickle.dump(mergedDic, pko)
    sp.run(f'rm {outdir}/tmp/{prefix}.*_*.{res}{bf}.matrix.pkl {outdir}/tmp/{prefix}.*_*.{res}{bf}.txt', shell=True)
    return mergedDic

def MakeChrompickle(outdir, prefix, bf, params):
    chrom, (res, chrStartFragNumDic) = params
    chromIFdic = dict()
    chrStart = chrStartFragNumDic[chrom]
    with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res}{bf}.txt') as i1, open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res}{bf}.matrix.pkl', 'wb') as p1:
        for line in i1:
            bin1, bin2, value = line.rstrip().split('\t')
            if bin1 == bin2:
                value = float(0)
            if value != 'NaN' and value != "nan":
                chromIFdic[f'{int(bin1)/res+chrStart:.0f}' + '\t' + f'{int(bin2)/res+chrStart:.0f}'] = float(value)
        pickle.dump(chromIFdic, p1)

def LoadIFpickleFile(infile):
    with open(infile, 'rb') as pk:
        chromIFdic = pickle.load(pk)
    return chromIFdic

def makeFullArray(outdir, prefix, Gene_minMaxFragDic, RElengthDic, chromlist, chromIFdic, t, bs, imgsize):
    pool = mp.Pool(processes=t)
    func_parallel = partial(ArrayParallelizing, outdir, prefix, Gene_minMaxFragDic, RElengthDic, bs, imgsize)
    pool.starmap(func_parallel, zip(chromlist, list(chromIFdic.values())))
    pool.close()
    pool.join()

def ArrayParallelizing(outdir, prefix, Gene_minMaxFragDic, RElengthDic, bs, imgsize, chrom, IFdic):
    sp.run(f"less {outdir}/tmp/{prefix}.region_addBoundary.txt | awk '$1==\"{chrom}\"' > {outdir}/tmp/{prefix}.region_addBoundary.{chrom}_{chrom}.txt", shell=True)

    geneArrayDic_resize = dict()
    with open(f'{outdir}/tmp/{prefix}.region_addBoundary.{chrom}_{chrom}.txt') as r1:
        for line in r1:
            geneid = line.split('\t')[3]
            minFrag, maxFrag = Gene_minMaxFragDic[geneid].split('\t')
            gl = np.sum(RElengthDic[geneid])
            col_array = makeArray(geneid, minFrag, maxFrag, RElengthDic[geneid], gl, bs, IFdic)
            try:
                pil_array = Image.fromarray(col_array)
                resized_array = np.array(pil_array.resize((imgsize,imgsize),Image.BILINEAR))
                resized_array[resized_array<0] = 0
            except ValueError:
                resized_arrag = np.zeros((imgsize, imgsize))
            geneArrayDic_resize[geneid] = resized_array
        with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.pkl','wb') as p2:
            pickle.dump(geneArrayDic_resize, p2)

def makeArray_original(geneid, minFrag, maxFrag, FraglengthList, gl, IFdic):
    
    A = np.zeros((gl,gl))
    start1=0
    end1=FraglengthList[0]-1

    for i in range(int(minFrag), int(maxFrag)+1):
        ## i=j
        start2 = start1
        end2 = end1

        for j in range(i, int(maxFrag)+1):
            try:
                IF = IFdic[str(i) + '\t' + str(j)]
            except KeyError:
                IF = 0
            A[start1:end1,start2:end2] = IF
            A[start2:end2,start1:end1] = IF
            if j == int(maxFrag):
                break
            start2 = start2 + FraglengthList[j - int(minFrag)]
            end2 = end2 + FraglengthList[j+1 - int(minFrag)]
        
        if i == int(maxFrag):
            break
        start1 = end1+1
        end1 = end1 + FraglengthList[i+1 -int(minFrag)]
    return A

def makeArray(gene_id, minFrag, maxFrag, FraglengthList, gl, bs, IFdic):
    
    A = np.zeros((gl//bs,gl//bs))
    start1=0
    end1=FraglengthList[0]

    for i in range(int(minFrag), int(maxFrag)+1):
        ## i=j
        start2 = start1
        end2 = end1

        for j in range(i, int(maxFrag)+1):
            try:
                IF = IFdic[str(i) + '\t' + str(j)]
            except KeyError:
                IF = 0
            A[start1//bs:end1//bs,start2//bs:end2//bs] = IF
            A[start2//bs:end2//bs,start1//bs:end1//bs] = IF
            if j == int(maxFrag):
                break
            start2 = start2 + FraglengthList[j - int(minFrag)]
            end2 = end2 + FraglengthList[j - int(minFrag) + 1]
        
        if i == int(maxFrag):
            break
        start1 = end1
        end1 = end1 + FraglengthList[i -int(minFrag) + 1]
    return A

def mergePickle(outdir, prefix):

    outdict = dict()
    for chrom in chromlist:
        with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.pkl', 'rb') as pk:
            genepk = pickle.load(pk)
            outdict.update(genepk)
        sp.call(f'rm {outdir}/tmp/{prefix}.{chrom}_{chrom}.pkl', shell=True, universal_newlines=True)
    with open(f'{outdir}/{prefix}.pkl','wb') as p2:
        pickle.dump(outdict, p2)

if __name__ == '__main__':

    args = parse_args()
    MaketmpDir(args.outdir)
    AddBoundary(args.chromSize, args.bedfile, args.padding, args.outdir, args.prefix)
    Gene_minMaxFragDic, RElengthDic = makeFragmentedGene(args.outdir, args.prefix, args.refile)
    chromlist, chrStartFragNumDic, chrEndFragNumDic, GeneStartDic, GeneEndDic, GeneStrandDic = getVariables(args.chromSize, args.refile, args.bedfile)

    start_time = time.time()
    if args.skip == False:
        print('\n--skip == False. Starting from a .hic file')
        print('Dump interaction matrices from a .hic file.....\n')
        DumpMatrix(args.outdir, args.prefix, args.juicertools, args.norm, args.hic, args.resolution, args.BP_FRAG, chromlist, args.threads)
        print(f'\nDump time : {time.time() - start_time}')

        print('\nMake interaction matrix.pkl.....\n')
        start_time = time.time()
        IFdic = MakeIFpickleFiles(args.outdir, args.prefix, chrStartFragNumDic, chromlist, args.resolution, args.BP_FRAG, args.threads)
        print(f'Get matrix time : {time.time() - start_time}')
    else:
        print(f'\n--skip == True. Starting from a pickle file : {args.infile}')
        IFdic = LoadIFpickleFile(args.infile)
        print(f'Load matrix time : {time.time() - start_time}')

    start_time = time.time()
    print('Make gene arrays...')
    makeFullArray(args.outdir, args.prefix, Gene_minMaxFragDic, RElengthDic, chromlist, IFdic, args.threads, args.binSize, args.imgSize)
    mergePickle(args.outdir, args.prefix)
    print('Running time :',time.time()-start_time)
    sp.call(f'rm {args.outdir}/tmp/{args.prefix}.region_addBoundary*.txt {args.outdir}/tmp/{args.prefix}.FragmentedGene*.txt', shell=True, universal_newlines=True)
    sys.exit()
