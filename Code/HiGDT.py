import subprocess as sp
import sys
import argparse
import os
import numpy as np
import pandas as pd
import pickle
from scipy import stats
from statsmodels.stats.multitest import multipletests
import time
import multiprocessing as mp
from functools import partial
import itertools

##usage
def parse_args():
    parser = argparse.ArgumentParser(description = "", formatter_class = argparse.RawTextHelpFormatter)
    parser.add_argument('-b', dest = 'bedfile', required=True, help = 
    '''Path to the .bed file which includes genic information.
The 4th column should contain the label of each element.
    ''')
    parser.add_argument('-c', dest = 'chromSize', required=True, help = 
    '''Path to the .chrom.sizes file.
    ''')
    parser.add_argument('-p', dest = 'prefix', required=True, help = 
    '''Prefix for naming output files.
    ''')
    parser.add_argument('-j', dest = 'juicertools', default = False, help = 
    '''Path to the juicer_tools.jar file. Not required if the "--skip" option is used.
    ''')
    parser.add_argument('-hic', dest = 'hic', default = False, help = 
    '''Path to the .hic file. Not required if the "--skip" option is used.
    ''')
    parser.add_argument('-n', dest = 'norm', default = "SCALE", help = 
    '''Normalization method. Choose one of ["NONE", "VC", "VC_SQRT", "KR", "SCALE"]. 
Not required if the "--skip" option is used.
Default = 'SCALE'.
    ''')
    parser.add_argument('--skip', dest = 'skip', action='store_true', help = 
    '''Use this flag to skip generating matrix.pkl file(s) from a .hic file. 
You can use this flag if you've previously generated matrix.pkl file(s) using HiGDT.py.
if set, -i1 {matrix.pkl} [-i2 {matrix2.pkl}] option(s) is required for input file(s).
    ''')
    parser.add_argument('-i1', dest = 'infile1', default = False, help = 
    '''Path to the input matrix.pkl file generated at resolution1 (r1).
By default, this file is generated at {outdir}/{prefix}.{resolution}{BP/FRAG}.matrix.pkl.
    ''')
    parser.add_argument('-i2', dest = 'infile2', default = False, help = 
    '''Path to the input matrix.pkl file generated at resolution2 (r2). 
Required only if r1 != r2.
    ''')

    parser.add_argument('-o', dest = 'outdir', default = './', help = 
    '''Path to the output directory where whole output files will be written.
Default = './'.
    ''')
    parser.add_argument('-bf', dest = 'BP_FRAG', default = "BP", help = 
    '''The unit of resolution; basepair or restriction fragment.
Choose one of ["BP", "FRAG"].
Default = 'BP'.
    ''')
    parser.add_argument('-f', dest = 'resfile', default = False, help = 
    '''Path to the space-delimited whole-genome digestion file.
Required only for restriction fragment resolution analysis.
This file can be generated by Juicer utils.
    ''')
    parser.add_argument('-r1', dest = 'resolution1', default = 250, type = int, help = 
    '''Resolution for single-gene domain analysis.
r1 = 250 (BP) or r1 = 1 (FRAG) is recommended if you have enough sequencing depth.
Default = 250 (BP). 
    ''')
    parser.add_argument('-r2', dest = 'resolution2', default = 500, type = int, help = 
    '''Resolution for multigene domain analysis.
r2 = 500 (BP) or r2 = 2 (FRAG) is recommended if you have enough sequencing depth.
Default = 500 (BP). 
    ''')
    parser.add_argument('-c1', dest = 'cutoff1', default = 0.05, type = float, help = 
    '''Statistical cutoff value for single-gene domain analysis.
Default = 0.05.
    ''')
    parser.add_argument('-c2', dest = 'cutoff2', default = 0.05, type = float, help = 
    '''P-value cutoff for multi-gene domain analysis.
Default = 0.05.
    ''')
    parser.add_argument('--pvalue', dest = 'fdr', action='store_false', help = 
    '''Using P-value instead of false discovery rate (fdr).
Default = False. (Use FDR)
    ''')
    parser.add_argument('-l', dest = 'lcut', default=1000, type=int, help = 
    '''The size cutoff (bp) of genes for the comparison. 
Should be larger than (resolution x 4).
Default = 1000.
    ''')
    parser.add_argument('-m', dest = 'maxMultiN', default = 10, type = int, help = 
    '''The maximum number of genes in a multi-gene domain.
Larger number may slow down the analysis.
Default = 10.
    ''')
    parser.add_argument('-d', dest = 'maxDist', default = 50000, type = int, help = 
    '''The maximum distance (bp) between the first and the last gene in a multi-gene domain. 
Default = 50000.
    ''')
    parser.add_argument('-t', dest = 'threads', default = 1, type = int, help = 
    '''Number of threads to use. Ideally equal to the number of chromosomes.
Default = 1.
    ''')
    return parser.parse_args()

def getVariables(chromsize, resfile1, resfile2, bedfile, lcut):
    chromLengthDic = dict()
    with open(chromsize) as c1:
        for line in c1:
            chrom, end = line.rstrip().split('\t')
            chromLengthDic[chrom] = int(end)
    chrStartFragNumDic1 = dict() ; chrStartFragNumDic2 = dict()
    chrStartEndFragList1 = sp.check_output(f'less {resfile1} | datamash groupby 1 min 4 max 4', shell=True, universal_newlines=True).strip().split('\n')
    chrStartEndFragList2 = sp.check_output(f'less {resfile2} | datamash groupby 1 min 4 max 4', shell=True, universal_newlines=True).strip().split('\n')
    for line in chrStartEndFragList1:
        chr, start, end = line.rstrip().split('\t')
        chrStartFragNumDic1[chr] = int(start)
    for line in chrStartEndFragList2:
        chr, start, end = line.rstrip().split('\t')
        chrStartFragNumDic2[chr] = int(start)

    startDic = dict() ; endDic = dict() ; strandDic = dict() ; filtered = list()
    with open(bedfile) as b1:
        for line in b1:
            _, start, end, geneid, _, strand = line.rstrip().split('\t')
            startDic[geneid] = start
            endDic[geneid] = end
            strandDic[geneid] = strand
            if int(end) - int(start) >= lcut:
                filtered.append(geneid)
    return list(chromLengthDic.keys()), chromLengthDic, chrStartFragNumDic1, chrStartFragNumDic2, startDic, endDic, strandDic, filtered

def MaketmpDir(outdir):
    if os.path.isdir(f'{outdir}') == False:
        os.mkdir(f'{outdir}')
    if os.path.isdir(f'{outdir}/tmp') == False:
        os.mkdir(f'{outdir}/tmp')

def DumpMatrix(outdir, prefix, juicer_tools, norm, hic, res1, res2, bf, chromlist, t):
    if res1 != res2:
        sp.run(f"parallel -j {t} \"java -jar {juicer_tools} dump oe {norm} {hic} {{1}} {{1}} {bf} {{2}} {outdir}/tmp/{prefix}.{{1}}_{{1}}.{{2}}{bf}.txt\" ::: $(echo {' '.join(chromlist)}) ::: $(echo {res1} {res2})", shell=True)
    else:
        sp.run(f"parallel -j {t} \"java -jar {juicer_tools} dump oe {norm} {hic} {{1}} {{1}} {bf} {{2}} {outdir}/tmp/{prefix}.{{1}}_{{1}}.{{2}}{bf}.txt\" ::: $(echo {' '.join(chromlist)}) ::: $(echo {res1})", shell=True)

def MakeIFpickleFiles(outdir, prefix, chrStartFragNumDic1, chrStartFragNumDic2, chromlist, res1, res2, bf, t):

    pool = mp.Pool(processes=t)
    func_parallel = partial(MakeChrompickle, outdir, prefix, bf)
    if res1 != res2:
        pool.map(func_parallel, itertools.product(chromlist, zip([res1,res2], [chrStartFragNumDic1,chrStartFragNumDic2])))
    else:
        pool.map(func_parallel, itertools.product(chromlist, zip([res1], [chrStartFragNumDic1])))
    pool.close()
    pool.join()
        
    mergedDic1 = dict()
    for chrom in chromlist:
        with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res1}{bf}.matrix.pkl', 'rb') as pk:
            mergedDic1[chrom] = pickle.load(pk)
    with open(f'{outdir}/{prefix}.{res1}{bf}.matrix.pkl','wb') as pko:
        pickle.dump(mergedDic1, pko)

    if res1 != res2:
        mergedDic2 = dict()
        for chrom in chromlist:
            with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res2}{bf}.matrix.pkl', 'rb') as pk:
                mergedDic2[chrom] = pickle.load(pk)
        with open(f'{outdir}/{prefix}.{res2}{bf}.matrix.pkl','wb') as pko:
            pickle.dump(mergedDic2, pko)

        return mergedDic1, mergedDic2
    return mergedDic1

def MakeChrompickle(outdir, prefix, bf, params):
    chrom, (res, chrStartFragNumDic) = params
    chromIFdic = dict()
    chrStart = chrStartFragNumDic[chrom]
    with open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res}{bf}.txt') as i1, open(f'{outdir}/tmp/{prefix}.{chrom}_{chrom}.{res}{bf}.matrix.pkl', 'wb') as p1:
        for line in i1:
            bin1, bin2, value = line.rstrip().split('\t')
            if bin1 == bin2:
                value = float(0)
            if value != 'NaN' and value != "nan":
                chromIFdic[f'{int(bin1)/res+chrStart:.0f}' + '\t' + f'{int(bin2)/res+chrStart:.0f}'] = float(value)
        pickle.dump(chromIFdic, p1)

def LoadIFpickleFile(infile):
    with open(infile, 'rb') as pk:
        chromIFdic = pickle.load(pk)
    return chromIFdic

def GetminMaxFragOfGene(bedfile, resfile, res, outdir, prefix, bf, chromlist):
    sp.run(f'bedtools intersect -a {bedfile} -b {resfile} -wo | datamash groupby 1,2,3,4,5,6 min 10 max 10 > {outdir}/tmp/{prefix}.FragmentGene.{res}{bf}.txt', shell=True) 
    Gene_minMaxFragDic = dict()
    for c in chromlist:
        Gene_minMaxFragDic[c] = dict()
    with open(f'{outdir}/tmp/{prefix}.FragmentGene.{res}{bf}.txt') as f1:
        for line in f1:
            chrom, _, _, geneid, _, _, m, M = line.rstrip().split('\t')
            Gene_minMaxFragDic[chrom][geneid] = (int(m),int(M))
    return Gene_minMaxFragDic

def makeFRAGbed(outdir, prefix, resfile, res1, res2):
    for r in [res1, res2]:
        with open(resfile) as r1, open(f'{outdir}/{prefix}.{r}FRAG.bed', 'w') as o1:
            n=1
            for line in r1:
                chr_name = line.split(' ')[0]
                frags = line.rstrip().split(' ')[1:]
                frags.insert(0,'1')
                
                for i in range((len(frags)-1)//r):
                    o1.write(chr_name + '\t' + frags[r*i] + '\t' + frags[r*(i+1)] + '\t' + str(n) + '\n')
                    n+=1
                if (len(frags)-1)%r!=0:
                    o1.write(chr_name + '\t' + frags[r*(i+1)] + '\t' + frags[-1] + '\t' + str(n) + '\n')
                    n+=1
    return f'{outdir}/{prefix}.{res1}FRAG.bed', f'{outdir}/{prefix}.{res2}FRAG.bed'

def makeBPbed(outdir, prefix, res1, res2, chromfile):
    for r in [res1, res2]:
        with open(chromfile) as f1, open(f'{outdir}/{prefix}.{r}BP.bed','w') as o1:
            x=1
            for line in f1:
                chrom, size = line.rstrip().split('\t')
                o1.write('\t'.join([chrom, '1', str(1*r), str(x)]) + '\n')
                for i in range(1,int(size)//r):
                    o1.write('\t'.join([chrom, str(i*r), str((i+1)*r), str(i+x)]) + '\n')
                o1.write('\t'.join([chrom, str((i+1)*r), size, str(i+x+1)]) + '\n')
                x=x+i+1
    return f'{outdir}/{prefix}.{res1}BP.bed', f'{outdir}/{prefix}.{res2}BP.bed'

def IdentifySingleGeneDomain(outdir, prefix, minMaxDic, IFdic, chromlist, window, cutoff, fdr, genelist, t, minN=3):
    pool = mp.Pool(processes=t)
    single_parallel = partial(CompareSingle, outdir, prefix, window, minN, cutoff, genelist)
    pool.starmap(single_parallel, zip(chromlist, list(IFdic.values()), list(minMaxDic.values())))
    pool.close()
    pool.join()

    chroms = ' '.join(chromlist)
    sp.run(f"parallel -j 1 \"cat {outdir}/tmp/{prefix}.{{1}}.single.tmp\" ::: $(echo {chroms}) > {outdir}/tmp/{prefix}.single.tmp", shell=True)

    single_df = pd.read_csv(f'{outdir}/tmp/{prefix}.single.tmp', sep='\t', header=None, names=['chrom', 'start', 'end', 'geneid', '1', 'strand', 'p'])
    single_df['q'] = multipletests(single_df['p'].values, method='fdr_bh')[1]
    if fdr == True:
        single_df.query('q < @cutoff').to_csv(f'{outdir}/{prefix}.SingleGeneDomain.txt', sep='\t', header=False, index=False)
    else:
        single_df.query('p < @cutoff').to_csv(f'{outdir}/{prefix}.SingleGeneDomain.txt', sep='\t', header=False, index=False)

def CompareSingle(outdir, prefix, window, minN, p_cutoff, filtered, chrom, IFdic, minMaxDic):
    gl = [g for g in list(minMaxDic.keys()) if g in filtered]
    with open(f'{outdir}/tmp/{prefix}.{chrom}.single.tmp', 'w') as o1:
        for target in gl:
            target_i, target_j = minMaxDic[target]
            w_size = int(window*(target_j - target_i + 1))
            w_shift = int(window*(target_j - target_i + 2))

            up_contact = [] ; target_contact = [] ; down_contact = []
            
            for i in range(target_i, target_j - w_shift + 1):
                for j in range(i + w_shift, target_j + 1):
                    try:
                        target_contact.append(IFdic[str(i) + '\t' + str(j)])
                    except KeyError:
                        target_contact.append(float(0))
                    try:
                        up_contact.append(IFdic[str(i - w_size) + '\t' + str(j - w_size)])
                    except KeyError:
                        up_contact.append(float(0))
                    try:
                        down_contact.append(IFdic[str(i + w_size) + '\t' + str(j + w_size)])
                    except KeyError:
                        down_contact.append(float(0))
                        
            if target_j - target_i >= minN:
                p = stats.mannwhitneyu(target_contact, up_contact+down_contact, alternative='greater')[1]
                o1.write('\t'.join([chrom, GeneStartDic[target], GeneEndDic[target], target, str(1), GeneStrandDic[target], str(p)]) + '\n')

def IdentifyMultiGeneDomain(outdir, prefix, chromLengthDic, minMaxDic, IFdic, chromlist, maxGeneN, maxDist, cutoff, fdr, t, minN=3):
    pool = mp.Pool(processes=t)
    single_parallel = partial(CompareMulti, outdir, prefix, minN, maxGeneN, maxDist, chromLengthDic)
    pool.starmap(single_parallel, zip(chromlist, list(IFdic.values()), list(minMaxDic.values())))
    pool.close()
    pool.join()

    chroms = ' '.join(chromlist)
    sp.run(f"parallel -j 1 \"cat {outdir}/tmp/{prefix}.{{1}}.multi.tmp\" ::: $(echo {chroms}) > {outdir}/tmp/{prefix}.multi.tmp", shell=True)

    multi_df = pd.read_csv(f'{outdir}/tmp/{prefix}.multi.tmp', sep='\t', header=None, names=['chrom', 'start', 'end', 'geneid', 'geneN', 'strand', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6'])
    multi_df['q1'] = multipletests(multi_df['p1'].values, method='fdr_bh')[1]
    multi_df['q2'] = multipletests(multi_df['p2'].values, method='fdr_bh')[1]
    multi_df['q3'] = multipletests(multi_df['p3'].values, method='fdr_bh')[1]
    multi_df['q4'] = multipletests(multi_df['p4'].values, method='fdr_bh')[1]
    multi_df['q5'] = multipletests(multi_df['p5'].values, method='fdr_bh')[1]
    multi_df['q6'] = multipletests(multi_df['p6'].values, method='fdr_bh')[1]
    if fdr == True:
        multi_df.query('(q1 < @cutoff) and (q2 < @cutoff) and (q3 < @cutoff) and (q4 < @cutoff) and (q5 < @cutoff) and (q6 < @cutoff)').to_csv(f'{outdir}/{prefix}.MultiGeneDomain.txt', sep='\t', header=False, index=False)
        multi_df.query('(q1 < @cutoff) and (q2 < @cutoff) and (q3 >= @cutoff) and (q4 >= @cutoff) and (q5 >= @cutoff) and (q6 >= @cutoff)').to_csv(f'{outdir}/{prefix}.GeneToGene.txt', sep='\t', header=False, index=False)
    else:
        multi_df.query('(p1 < @cutoff) and (p2 < @cutoff) and (p3 < @cutoff) and (p4 < @cutoff) and (p5 < @cutoff) and (p6 < @cutoff)').to_csv(f'{outdir}/{prefix}.MultiGeneDomain.txt', sep='\t', header=False, index=False)
        multi_df.query('(p1 < @cutoff) and (p2 < @cutoff) and (p3 >= @cutoff) and (p4 >= @cutoff) and (p5 >= @cutoff) and (p6 >= @cutoff)').to_csv(f'{outdir}/{prefix}.GeneToGene.txt', sep='\t', header=False, index=False)

def CompareMulti(outdir, prefix, minN, maxGeneN, maxDist, chromLengthDic, chrom, IFdic, minMaxDic):
    gl = list(minMaxDic.keys())
    with open(f'{outdir}/tmp/{prefix}.{chrom}.multi.tmp', 'w') as o1:
        i = 0
        chrom_end = chromLengthDic[chrom]
        while i < len(gl) - 1:
            m = 1
            target_start = int(GeneStartDic[gl[i]])
            target_end = int(GeneEndDic[gl[i]])
            while 1:
                if i+m == len(gl):
                    break
                else:
                    pair_start = int(GeneStartDic[gl[i+m]])
                    pair_end = int(GeneEndDic[gl[i+m]])
                ### At the last gene of chromosome || Max number of genes in a multigene domain || Larger than maximum gap between gene pairs
                if m >= maxGeneN or pair_start-target_end > maxDist:
                    break 
                ### At both chromosome ends, no data points obtained for controls
                elif target_start - (pair_end - target_end) < 0 or pair_end + (pair_start - target_start) > chrom_end:
                    break
                elif minMaxDic[gl[i+m]][1] - minMaxDic[gl[i]][0] >= minN:

                    p1, p2 = GeneToGene(minMaxDic, IFdic, gl[i], gl[i+m])
                    p3, p4 = FivePrimeBoundary(minMaxDic, IFdic, gl[i], gl[i+1], gl[i+m])
                    p5, p6 = ThreePrimeBoundary(minMaxDic, IFdic, gl[i], gl[i+m-1], gl[i+m])
                    plist = [str(p1), str(p2), str(p3), str(p4), str(p5), str(p6)]
                    genes = gl[i:i+m+1]
                    strands = list(GeneStrandDic[g] for g in genes)
                    o1.write(chrom + '\t' + GeneStartDic[gl[i]] + '\t' + GeneEndDic[gl[i+m]] + '\t' + ':'.join(genes) + '\t' + str(m+1) + '\t' + ':'.join(strands) + '\t' + '\t'.join(plist) + '\n')
                m+=1
            i+=1

def GeneToGene(minMaxDic, IFdic, target, down):
    target_i, target_j = minMaxDic[target]
    down_i, down_j = minMaxDic[down]
    target_contact = [] ; up_contact = [] ; down_contact = []
    for i in range(target_i, target_j+1):
        for j in range(down_i, down_j+1):
            try:
                target_contact.append(IFdic[str(i) + '\t' + str(j)])
            except KeyError:
                target_contact.append(float(0))
            try:
                up_contact.append(IFdic[str(target_i - (j-target_j)) + '\t' + str(i)])
            except KeyError:
                up_contact.append(float(0))
            try:
                down_contact.append(IFdic[str(j) + '\t' + str(down_j + down_i - i)])
            except KeyError:
                down_contact.append(float(0))
    p1 = stats.mannwhitneyu(target_contact, up_contact, alternative='greater')[1]
    p2 = stats.mannwhitneyu(target_contact, down_contact, alternative='greater')[1]
    return p1, p2

def FivePrimeBoundary(minMaxDic, IFdic, target, target_next, down):
    target_i, target_j = minMaxDic[target]
    down_i = minMaxDic[target_next][0]
    down_j = minMaxDic[down][1]
    target_contact = [] ; up_contact = [] ; down_contact = []
    for i in range(target_i, target_j+1):
        for j in range(down_i, down_j+1):
            try:
                target_contact.append(IFdic[str(i) + '\t' + str(j)])
            except KeyError:
                target_contact.append(float(0))
            try:
                up_contact.append(IFdic[str(target_i - (j-target_j)) + '\t' + str(i)])
            except KeyError:
                up_contact.append(float(0))
            try:
                down_contact.append(IFdic[str(j) + '\t' + str(down_j + down_i - i)])
            except KeyError:
                down_contact.append(float(0))
    try:
        p3 = stats.mannwhitneyu(target_contact, up_contact, alternative='greater')[1]
        p4 = stats.mannwhitneyu(target_contact, down_contact, alternative='greater')[1]
    except ValueError:
        print(target, down, target_i, target_j, down_i, down_j, target_contact, up_contact, down_contact)
    return p3, p4

def ThreePrimeBoundary(minMaxDic, IFdic, target, before_down, down):
    target_i = minMaxDic[target][0]
    target_j = minMaxDic[before_down][1]
    down_i, down_j = minMaxDic[down]
    target_contact = [] ; up_contact = [] ; down_contact = []
    for i in range(target_i, target_j+1):
        for j in range(down_i, down_j+1):
            try:
                target_contact.append(IFdic[str(i) + '\t' + str(j)])
            except KeyError:
                target_contact.append(float(0))
            try:
                up_contact.append(IFdic[str(j) + '\t' + str(down_j + down_i - i)])
            except KeyError:
                up_contact.append(float(0))
            try:
                down_contact.append(IFdic[str(target_i - (j - target_j)) + '\t' + str(i)])
            except KeyError:
                down_contact.append(float(0))
    p5 = stats.mannwhitneyu(target_contact, up_contact, alternative='greater')[1]
    p6 = stats.mannwhitneyu(target_contact, down_contact, alternative='greater')[1]
    return p5, p6

def MakeAdditionalFiles(outdir, prefix, t):
    sp.run(f"cat {outdir}/{prefix}.SingleGeneDomain.txt {outdir}/{prefix}.MultiGeneDomain.txt | sort -k1,1 -k2,2n -k3,3n > {outdir}/{prefix}.MergedGeneDomain.txt", shell=True)
    sp.run(f"parallel -j {t} \"less {outdir}/{prefix}.{{1}}GeneDomain.txt | awk '{{print \$1, \$2, \$3, \$1, \$2, \$3}}' OFS='\t' > {outdir}/{prefix}.{{1}}GeneDomain.juicebox.bed\" ::: $(echo Single Multi Merged)", shell=True)

def tmpClearing(outdir, prefix, res1, res2, BP_FRAG):
    sp.run(f"rm {outdir}/tmp/{prefix}.*.tmp {outdir}/tmp/{prefix}.Chr*.txt {outdir}/tmp/{prefix}.*_*.{res1}{BP_FRAG}.matrix.pkl \
    {outdir}/tmp/{prefix}.*_*.{res2}{BP_FRAG}.matrix.pkl {outdir}/tmp/{prefix}.FragmentGene.{res1}{BP_FRAG}.txt \
    {outdir}/tmp/{prefix}.FragmentGene.{res2}{BP_FRAG}.txt", shell=True)
    

if __name__ == '__main__':
    args = parse_args()

    MaketmpDir(args.outdir)
    if args.BP_FRAG == "BP":
        if args.resolution1 < 100 or args.resolution2 < 100:
            print(f'### Too high resolution is defined : {args.BP_FRAG} -- {args.resolution1}, {args.resolution2}')
            sys.exit()
        resfile1, resfile2 = makeBPbed(args.outdir, args.prefix, args.resolution1, args.resolution2, args.chromSize)
    elif args.BP_FRAG == "FRAG":
        if args.resolution1 >= 100 or args.resolution2 >= 100:
            print(f'### Too low resolution is defined : {args.BP_FRAG} -- {args.resolution1}, {args.resolution2}')
        if args.resfile == False:
            print('###Error### Restriction fragment file is required.')
            sys.exit()
        resfile1, resfile2 = makeFRAGbed(args.outdir, args.prefix, args.resfile, args.resolution1, args.resolution2)
    else:
        print(f'###Error### Wrong BP_FRAG name : {args.BP_FRAG}')
        sys.exit()
    
    chromlist, chromLengthDic, chrStartFragNumDic1, chrStartFragNumDic2, GeneStartDic, GeneEndDic, GeneStrandDic, genelist = getVariables(args.chromSize, resfile1, resfile2, args.bedfile, args.lcut)
    print('\n HiGDT -- version 1.0.0')
    start_time = time.time()
    if args.skip == False:
        print('\n--skip == False. Starting from a .hic file')
        print('Dump interaction matrices from a .hic file.....\n')
        DumpMatrix(args.outdir, args.prefix, args.juicertools, args.norm, args.hic, args.resolution1, args.resolution2, args.BP_FRAG, chromlist, args.threads)
        print('Make interaction matrix.pkl.....\n')
        if args.resolution1 == args.resolution2:
            IFdic1 = MakeIFpickleFiles(args.outdir, args.prefix, chrStartFragNumDic1, chrStartFragNumDic2, chromlist, args.resolution1, args.resolution2, args.BP_FRAG, args.threads)
        else:
            IFdic1, IFdic2 = MakeIFpickleFiles(args.outdir, args.prefix, chrStartFragNumDic1, chrStartFragNumDic2, chromlist, args.resolution1, args.resolution2, args.BP_FRAG, args.threads)
        print(f'Dump time : {time.time() - start_time}')
    else:
        print(f'\n--skip == True. Starting from pickle file(s)')
        print('\nLoading first pickle file.....')
        start_time = time.time()
        IFdic1 = LoadIFpickleFile(args.infile1)
        if args.resolution1 != args.resolution2:
            print('Loading second pickle file.....')
            IFdic2 = LoadIFpickleFile(args.infile2)
        print(f'loading time : {time.time() - start_time}')
    
    start_time = time.time()
    Gene_minMaxFragDic1 = GetminMaxFragOfGene(args.bedfile, resfile1, args.resolution1, args.outdir, args.prefix, args.BP_FRAG, chromlist)
    if args.resolution1 != args.resolution2:
        Gene_minMaxFragDic2 = GetminMaxFragOfGene(args.bedfile, resfile2, args.resolution2, args.outdir, args.prefix, args.BP_FRAG, chromlist)
        print(f'Analyzing multi gene domains.....')
        IdentifyMultiGeneDomain(args.outdir, args.prefix, chromLengthDic, Gene_minMaxFragDic2, IFdic2, chromlist, args.maxMultiN, args.maxDist, args.cutoff2, args.fdr, args.threads)
        print(f'Completed. time : {time.time() - start_time}')
    else:
        start_time = time.time()
        print(f'Analyzing multi gene domains.....')
        IdentifyMultiGeneDomain(args.outdir, args.prefix, chromLengthDic, Gene_minMaxFragDic1, IFdic1, chromlist, args.maxMultiN, args.maxDist, args.cutoff2, args.fdr, args.threads)
        print(f'Completed. time : {time.time() - start_time}')
    
    start_time = time.time()
    print('\nAnalyzing single gene domains.....')
    IdentifySingleGeneDomain(args.outdir, args.prefix, Gene_minMaxFragDic1, IFdic1, chromlist, 0.5, args.cutoff1, args.fdr, genelist, args.threads)
    print(f'Completed. time : {time.time() - start_time}')
    
    MakeAdditionalFiles(args.outdir, args.prefix, args.threads)
    tmpClearing(args.outdir, args.prefix, args.resolution1, args.resolution2, args.BP_FRAG)
    print(f'All analysis completed.\n')
